import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import nltk
nltk.download('vader_lexicon')

# Load the dataset (replace with actual path)
df = pd.read_csv('path_to_amazon_reviews.csv')

# Display first few rows
print(df.head())

# Categorizing feedback (Topic Modeling using LDA)
vectorizer = CountVectorizer(stop_words='english')
X = vectorizer.fit_transform(df['reviewText'])
lda = LatentDirichletAllocation(n_components=5, random_state=42)
lda.fit(X)

# Display top words for each topic
def display_topics(model, feature_names, no_top_words):
    for topic_idx, topic in enumerate(model.components_):
        print(f"Topic {topic_idx}:")
        print(" ".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))

display_topics(lda, vectorizer.get_feature_names_out(), 10)

# Sentiment Analysis using VADER
sid = SentimentIntensityAnalyzer()
df['sentiment'] = df['reviewText'].apply(lambda x: sid.polarity_scores(x)['compound'])

print(df[['reviewText', 'sentiment']].head())

# Quantifying customer satisfaction (NPS categorization)
df['satisfaction'] = df['overall'].apply(lambda x: 'Promoter' if x >= 9 else ('Detractor' if x <= 6 else 'Passive'))

print(df[['reviewText', 'overall', 'satisfaction']].head())

# Save results
df.to_csv('customer_feedback_analysis.csv', index=False)

# Visualization of Sentiment Distribution
plt.figure(figsize=(10, 6))
sns.histplot(df['sentiment'], bins=20, kde=True)
plt.title('Sentiment Distribution')
plt.xlabel('Sentiment Score')
plt.ylabel('Frequency')
plt.show()

# Visualization of Customer Satisfaction
plt.figure(figsize=(10, 6))
sns.countplot(x='satisfaction', data=df)
plt.title('Customer Satisfaction Distribution')
plt.xlabel('Satisfaction Category')
plt.ylabel('Frequency')
plt.show()
